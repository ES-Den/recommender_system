# Рекомендательная система для публикаций социальной сети
---
Перед нами классичесая социальная сеть, в которой пользователи могут общаться, заводить новых друзей, присоединяться к группам, просматривать публикации в персональной ленте или ленте своих друзей. Мы заинтересованы, чтобы показанные публикации пользователям были наиболее релевантными. Что увеличит вовлечение наших клиентов в социальную сеть и они будут проводить больше времени в ней.
# Алгоритм работы сервиса
---
По ID пользователя и на текущую дату сервис должен выдавать 5 наиболее релевантых публикаций для данного user.
# Этапы проекта
---
1. Загрузка данных из базы данных. Проведение анализа.
2. Подготовка качественных признаков для обучения модели.
3. Выбор оптимальной модели машинного обучения. Оценка качества.
4. Загрузка предподготовленных признаков в базу данных.
5. Написание сервиса: загрузка модели -> получение признаков для модели по user_id -> предсказание постов, которые лайкнут -> возвращение ответа.
## Использованные инструменты
__ML модель__: CatBoostClassifier.
__Анализ__: python, pandas, numpy, mathplotlib, seaborn, scikit-learn.
__Feature engeneering__: scikit-learn, PCA, TfIdf, K-Means.
__Бэкэнд-сервис__: FastApi, SQLAlchemy.
## Краткое описание таблиц в базе данных
* ```user_data``` - сведения о пользователях при регистрации(id, пол, возраст, город, страна и др.).
* ```post_text_df``` - описание публикаций(id, текс, топик (тема)).
* ```feed_post``` - пользовательский опыт за определенный период(id юзера, id поста, действие (лайк/просмотр).
## Oбучение и выбор модели, оценка качества
В рабочей директории к проекту вы можете найти JupiterNotebook __recom_system.ipynb__, где подробным образом отображены все этапы проекта от анализа, отбора и генерации новых признаков, выбор оптимальной модели, оценки качества.
__post_feature.ipynb__  содержит в себе обработку текста и получение текстовых признаков. 
__model__ - предобученная модель
__endpoint.py__ - скрипт, в котором происходят следущие этапы:
* выгрузка предподготовленных признаков для обучения модели из базы данных
* загрузка предобученной модели
* формируем массив признаков для модели по одному пользователю 
* получаем предсказания модели 
* выбираем топ-5 с наибольшей вероятностью

__schema.py__ - модели pydentic

__requirements.txt__ - необходимые библиотеки